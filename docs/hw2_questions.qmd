---
title: "Poisson Regression Examples"
author: "Sarah Howard"
date: 12 May 2025
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---


## Blueprinty Case Study

### Introduction
##testing

Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty's software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty's software and after using it. Unfortunately, such data is not available. 

However, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm's number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty's software. The marketing team would like to use this data to make the claim that firms using Blueprinty's software are more successful in getting their patent applications approved.


### Data

_todo: Read in data._

_todo: Compare histograms and means of number of patents by customer status. What do you observe?_

Blueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.

_todo: Compare regions and ages by customer status. What do you observe?_


### Estimation of Simple Poisson Model

Since our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.

_todo: Write down mathematically the likelihood for_ $Y \sim \text{Poisson}(\lambda)$. Note that $f(Y|\lambda) = e^{-\lambda}\lambda^Y/Y!$.

_todo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:_

```
poisson_loglikelihood <- function(lambda, Y){
   ...
}
```

_todo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y)._

_todo: If you're feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which "feels right" because the mean of a Poisson distribution is lambda._

_todo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python._


### Estimation of Poisson Regression Model

Next, we extend our simple Poisson model to a Poisson Regression Model such that $Y_i = \text{Poisson}(\lambda_i)$ where $\lambda_i = \exp(X_i'\beta)$. The interpretation is that the success rate of patent awards is not constant across all firms ($\lambda$) but rather is a function of firm characteristics $X_i$. Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.

_todo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that_ $\lambda_i = e^{X_i'\beta}$. _For example:_

```
poisson_regression_likelihood <- function(beta, Y, X){
   ...
}
```

_todo: Use your function along with R's optim() or Python's sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1's to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors._

_todo: Check your results using R's glm() function or Python sm.GLM() function._

_todo: Interpret the results._ 

_todo: What do you conclude about the effect of Blueprinty's software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences._




## AirBnB Case Study

### Introduction

AirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City.  The data include the following variables:

:::: {.callout-note collapse="true"}
### Variable Definitions

    - `id` = unique ID number for each unit
    - `last_scraped` = date when information scraped
    - `host_since` = date when host first listed the unit on Airbnb
    - `days` = `last_scraped` - `host_since` = number of days the unit has been listed
    - `room_type` = Entire home/apt., Private room, or Shared room
    - `bathrooms` = number of bathrooms
    - `bedrooms` = number of bedrooms
    - `price` = price per night (dollars)
    - `number_of_reviews` = number of reviews for the unit on Airbnb
    - `review_scores_cleanliness` = a cleanliness score from reviews (1-10)
    - `review_scores_location` = a "quality of location" score from reviews (1-10)
    - `review_scores_value` = a "quality of value" score from reviews (1-10)
    - `instant_bookable` = "t" if instantly bookable, "f" if not

::::


_todo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided._

```python
#| label: load-blueprinty-data
#| echo: true
import pandas as pd

# Load the dataset
blueprinty_df = pd.read_csv("blueprinty.csv")
blueprinty_df['region'] = blueprinty_df['region'].astype('category')

```


```python
#| label: histogram-patents
#| fig-cap: "Histogram of Patents by Customer Status"
#| echo: true
import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid")
plt.figure(figsize=(8, 5))
sns.histplot(data=blueprinty_df, x='patents', hue='iscustomer', multiple='dodge', bins=15)
plt.title('Distribution of Patents by Customer Status')
plt.xlabel('Number of Patents')
plt.ylabel('Count')
plt.show()

```


    
![png](output_1_0.png)
    



```python
#| label: mean-patents
#| echo: true
# Compare mean number of patents by customer status
blueprinty_df.groupby('iscustomer')['patents'].mean()

```




    iscustomer
    0    3.473013
    1    4.133056
    Name: patents, dtype: float64




```python
#| label: boxplot-age
#| fig-cap: "Boxplot of Firm Age by Customer Status"
#| echo: true
plt.figure(figsize=(6, 4))
sns.boxplot(data=blueprinty_df, x='iscustomer', y='age')
plt.title('Firm Age by Customer Status')
plt.xlabel('Customer Status (0 = Non, 1 = Yes)')
plt.ylabel('Firm Age')
plt.show()

```


    
![png](output_3_0.png)
    



```python
#| label: age-summary
#| echo: true
# Summary statistics of firm age by customer status
blueprinty_df.groupby('iscustomer')['age'].describe()

```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>iscustomer</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1019.0</td>
      <td>26.101570</td>
      <td>6.945426</td>
      <td>9.0</td>
      <td>21.0</td>
      <td>25.5</td>
      <td>31.25</td>
      <td>47.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>481.0</td>
      <td>26.900208</td>
      <td>7.814678</td>
      <td>10.0</td>
      <td>20.5</td>
      <td>26.5</td>
      <td>32.50</td>
      <td>49.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
#| label: region-distribution
#| fig-cap: "Regional Distribution of Firms by Customer Status"
#| echo: true
plt.figure(figsize=(8, 5))
sns.countplot(data=blueprinty_df, x='region', hue='iscustomer')
plt.title('Region by Customer Status')
plt.xlabel('Region')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

```


    
![png](output_5_0.png)
    



```python
#| label: region-summary
#| echo: true
# Tabulate number of firms per region by customer status
blueprinty_df.groupby(['region', 'iscustomer']).size().unstack()

```

    /tmp/ipykernel_48627/3320520734.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
      blueprinty_df.groupby(['region', 'iscustomer']).size().unstack()





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>iscustomer</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>region</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Midwest</th>
      <td>187</td>
      <td>37</td>
    </tr>
    <tr>
      <th>Northeast</th>
      <td>273</td>
      <td>328</td>
    </tr>
    <tr>
      <th>Northwest</th>
      <td>158</td>
      <td>29</td>
    </tr>
    <tr>
      <th>South</th>
      <td>156</td>
      <td>35</td>
    </tr>
    <tr>
      <th>Southwest</th>
      <td>245</td>
      <td>52</td>
    </tr>
  </tbody>
</table>
</div>



### Observations and Interpretation

Firms that use Blueprinty's software appear to differ systematically from those that do not in several key ways:

1. **Patent Output**  
   - Blueprinty customers have a higher average number of patents (~4.13) compared to non-customers (~3.47).  
   - The distribution is skewed right for both groups, but customers are slightly more likely to have higher patent counts.  
   - This could suggest that Blueprinty customers are more productive or successful—but we must be cautious before attributing this difference to software usage alone.

2. **Firm Age**  
   - Customers are slightly older on average (mean age ~26.9 years) compared to non-customers (~26.1 years).  
   - The difference is not dramatic, but could reflect that more established firms are more likely to adopt Blueprinty’s tools.

3. **Regional Location**  
   - Blueprinty’s customer base is heavily concentrated in the **Northeast** region, which accounts for 68% of customer firms.  
   - In contrast, the Northeast only represents 27% of non-customer firms.  
   - This concentration suggests regional adoption trends and also indicates that region must be controlled for in the


Since our outcome variable of interest—the number of patents awarded—is a non-negative integer count over a fixed time period (5 years), it is well-suited to modeling using the Poisson distribution.

The probability mass function of the Poisson distribution is:

$$
f(Y \mid \lambda) = \frac{e^{-\lambda} \lambda^Y}{Y!}
$$

The corresponding log-likelihood for a sample of \( n \) independent observations is:

$$
\log L(\lambda) = \sum_{i=1}^n \left( Y_i \log \lambda - \lambda - \log(Y_i!) \right)
$$

Below, we define this log-likelihood in Python and visualize how it changes across values of \( \lambda \).



```python
#| label: poisson-loglikelihood-plot
#| fig-cap: "Poisson Log-Likelihood as a Function of Lambda"
import numpy as np
import matplotlib.pyplot as plt
from scipy.special import factorial

Y_obs = blueprinty_df["patents"].values

def poisson_loglikelihood(lmbda, Y):
    if lmbda <= 0:
        return -np.inf
    return np.sum(Y * np.log(lmbda) - lmbda - np.log(factorial(Y)))

lambda_vals = np.linspace(0.1, 10, 200)
loglik_vals = [poisson_loglikelihood(lmbda, Y_obs) for lmbda in lambda_vals]

plt.figure(figsize=(8, 5))
plt.plot(lambda_vals, loglik_vals)
plt.xlabel("Lambda (λ)")
plt.ylabel("Log-Likelihood")
plt.title("Poisson Log-Likelihood vs. Lambda")
plt.grid(True)
plt.show()

```


    
![png](output_9_0.png)
    


We can analytically derive the MLE for \( \lambda \) by setting the derivative of the log-likelihood equal to zero. This yields:

$$
\hat{\lambda}_{MLE} = \bar{Y}
$$

This result makes intuitive sense, as the Poisson distribution's mean is \( \lambda \). Let's compute this both analytically and via numerical optimization:



```python
#| label: poisson-mle-estimation
#| echo: true
from scipy.optimize import minimize

lambda_mle_analytic = np.mean(Y_obs)

def neg_loglik(lmbda):
    return -poisson_loglikelihood(lmbda[0], Y_obs)

result = minimize(neg_loglik, x0=[1.0], bounds=[(1e-6, None)])
lambda_mle_numerical = result.x[0]

lambda_mle_analytic, lambda_mle_numerical

```




    (3.6846666666666668, 3.684666485763343)



We now extend the Poisson model to include covariates using a log-linear model:

$$
Y_i \sim \text{Poisson}(\lambda_i), \quad \text{where } \lambda_i = \exp(X_i^\top \beta)
$$

This allows the expected number of patents to depend on firm characteristics such as age, region, and Blueprinty customer status. We estimate the model parameters using Maximum Likelihood Estimation (MLE).


We fit a Poisson regression model to estimate the effect of firm characteristics on the number of awarded patents. The model includes:

- Age and age squared (to capture nonlinear age effects),
- Region fixed effects (with Midwest as the reference category),
- A binary indicator for whether the firm uses Blueprinty software.

The coefficient on `iscustomer` is approximately **0.208**, and is statistically significant. This suggests that, all else equal, being a Blueprinty customer is associated with a higher expected number of patents.



```python
import pandas as pd
airbnb_df = pd.read_csv("airbnb.csv")

```


```python
airbnb_clean = airbnb_df.copy()

```

### 📋 Interpretation of Poisson Regression Results

We modeled the number of reviews a listing receives (used as a proxy for the number of bookings) using a Poisson regression model. The predictors included:

- Number of days listed on the platform (`days`)
- Number of bathrooms and bedrooms
- Review scores for cleanliness, location, and value
- Whether the listing is instantly bookable
- Price (standardized)
- Room type (Private and Shared rooms, with Entire home/apt as the reference category)

---

### 🧾 Key Results

- **Intercept**





