[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sarah Howard",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Howard Website HW1",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard‚Äôs Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard‚Äôs Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription"
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic ‚Äúworks,‚Äù in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. You‚Äôll then calculate a vector of 10,000 differences, and then you‚Äôll plot the cumulative average of that vector of differences. This average will likely be ‚Äúnoisey‚Äù when only averaging a few numbers, but should ‚Äúsettle down‚Äù and approximate the treatment effect (0.004 = 0.022 - 0.018) as the sample size gets large. Explain the chart to the reader.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms at sample sizes 50, 200, 500, and 1000. To do this for a sample size of e.g.¬†50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. The repeat for the other 3 histograms. Explain this sequence of histograms and its relationship to the central limit theorem to the reader."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Sarah Howard",
    "section": "",
    "text": "title: ‚ÄúResume‚Äù format: hmtl: default typst: default Download PDF file. Welcome to my website!"
  },
  {
    "objectID": "hw1_questions.html#overview",
    "href": "hw1_questions.html#overview",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Overview",
    "text": "Overview\nThis dataset contains data from a large-scale natural field experiment investigating how different types of matching grants influence charitable giving.\n\nTotal Observations: 50,083 individuals\n\nVariables: 51\n\nSource: Does Price Matter in Charitable Giving? (Karlan & List, 2007)"
  },
  {
    "objectID": "hw1_questions.html#experimental-design-variables",
    "href": "hw1_questions.html#experimental-design-variables",
    "title": "A Replication of Karlan and List (2007)",
    "section": "üéØ Experimental Design Variables",
    "text": "üéØ Experimental Design Variables\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\n1 if participant received a matching grant offer, 0 if control group\n\n\nratio\nCategorical: Match ratio (e.g., 1:1, 2:1, 3:1)\n\n\nratio2, ratio3\nDummies for 2:1 and 3:1 match conditions\n\n\nsize\nCategorical: Maximum match size ($25k, $50k, $100k, or unstated)\n\n\nsize25, size50, size100, sizeno\nDummy variables for match size\n\n\nask1, ask2, ask3\nSuggested donation amounts (based on prior giving)"
  },
  {
    "objectID": "hw1_questions.html#donation-behavior-variables",
    "href": "hw1_questions.html#donation-behavior-variables",
    "title": "A Replication of Karlan and List (2007)",
    "section": "üí∏ Donation Behavior Variables",
    "text": "üí∏ Donation Behavior Variables\n\n\n\nVariable\nDescription\n\n\n\n\ngave\nBinary: 1 if donated, 0 otherwise\n\n\namount\nAmount donated (USD)\n\n\namountchange\nChange in amount donated vs.¬†previous gift"
  },
  {
    "objectID": "hw1_questions.html#demographic-zip-code-level-data",
    "href": "hw1_questions.html#demographic-zip-code-level-data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "üßë‚Äçü§ù‚Äçüßë Demographic & ZIP Code-level Data",
    "text": "üßë‚Äçü§ù‚Äçüßë Demographic & ZIP Code-level Data\n\n\n\nVariable\nDescription\n\n\n\n\npwhite, pblack\nProportion of white and Black residents\n\n\npage18_39\nProportion aged 18‚Äì39\n\n\nave_hh_sz\nAverage household size\n\n\nmedian_hhincome\nMedian household income\n\n\npowner\nProportion of homeowners\n\n\npsch_atlstba\nProportion with at least a bachelor‚Äôs degree\n\n\npop_propurban\nProportion of population in urban areas"
  },
  {
    "objectID": "hw1_questions.html#political-context-variables",
    "href": "hw1_questions.html#political-context-variables",
    "title": "A Replication of Karlan and List (2007)",
    "section": "üó≥Ô∏è Political Context Variables",
    "text": "üó≥Ô∏è Political Context Variables\n\n\n\nVariable\nDescription\n\n\n\n\nred0, blue0\nBinary: Red or blue state indicator\n\n\nredcty, bluecty\nBinary: Red or blue county indicator"
  },
  {
    "objectID": "hw1_questions.html#missing-data",
    "href": "hw1_questions.html#missing-data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "‚ùó Missing Data",
    "text": "‚ùó Missing Data\nSome variables (especially demographic ones) have missing values for ~2,000 cases due to ZIP-level data availability.\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\nBalance Test\n\n\n‚úÖ Randomization Check: Treatment vs.¬†Control Group Balance\nTo test the integrity of the random assignment, we compared several background variables between treatment and control groups using t-tests.\n\nüîç Variables Tested:\n\nmrm2: Months since last donation\n\nyears: Years since first donation\n\nhpa: Highest prior donation\n\nfemale: Female indicator\n\ncouple: Couple indicator\n\n\n\nüìà Key Findings:\n\nNo statistically significant differences (p &gt; 0.05) were found between groups for any variable tested.\nFor mrm2, both a t-test and a linear regression (mrm2 ~ treatment) produced the same result (p = 0.905), confirming the methods agree.\n\n\n\nüß† Why It Matters:\nThese tests confirm that the treatment and control groups were statistically similar before the intervention ‚Äî supporting the internal validity of the experiment.\nThis is the purpose of Table 1 in the paper: to demonstrate that any differences in donation behavior can be attributed to the matching grant treatment, not pre-existing group differences.\n\n\n\nExperimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\nüìä Response Rate by Treatment Group\nWe visualize whether being offered a matching donation affects the likelihood of donating. This barplot compares the donation response rate between the treatment and control groups.\n\nimport pandas as pd\n\n# Load the dataset (make sure the file is in the same directory as your notebook)\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Take a quick look at the first few rows\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows √ó 51 columns\n\n\n\n\n\n\n\n\n\n\n\ntreatment\n\n\ncontrol\n\n\nratio\n\n\nratio2\n\n\nratio3\n\n\nsize\n\n\nsize25\n\n\nsize50\n\n\nsize100\n\n\nsizeno\n\n\n‚Ä¶\n\n\nredcty\n\n\nbluecty\n\n\npwhite\n\n\npblack\n\n\npage18_39\n\n\nave_hh_sz\n\n\nmedian_hhincome\n\n\npowner\n\n\npsch_atlstba\n\n\npop_propurban\n\n\n\n\n\n\n0\n\n\n0\n\n\n1\n\n\nControl\n\n\n0\n\n\n0\n\n\nControl\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n‚Ä¶\n\n\n0.0\n\n\n1.0\n\n\n0.446493\n\n\n0.527769\n\n\n0.317591\n\n\n2.10\n\n\n28517.0\n\n\n0.499807\n\n\n0.324528\n\n\n1.0\n\n\n\n\n1\n\n\n0\n\n\n1\n\n\nControl\n\n\n0\n\n\n0\n\n\nControl\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n‚Ä¶\n\n\n1.0\n\n\n0.0\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\n2\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n$100,000\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n‚Ä¶\n\n\n0.0\n\n\n1.0\n\n\n0.935706\n\n\n0.011948\n\n\n0.276128\n\n\n2.48\n\n\n51175.0\n\n\n0.721941\n\n\n0.192668\n\n\n1.0\n\n\n\n\n3\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\nUnstated\n\n\n0\n\n\n0\n\n\n0\n\n\n1\n\n\n‚Ä¶\n\n\n1.0\n\n\n0.0\n\n\n0.888331\n\n\n0.010760\n\n\n0.279412\n\n\n2.65\n\n\n79269.0\n\n\n0.920431\n\n\n0.412142\n\n\n1.0\n\n\n\n\n4\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n$50,000\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n‚Ä¶\n\n\n0.0\n\n\n1.0\n\n\n0.759014\n\n\n0.127421\n\n\n0.442389\n\n\n1.85\n\n\n40908.0\n\n\n0.416072\n\n\n0.439965\n\n\n1.0\n\n\n\n\n\n5 rows √ó 51 columns\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Calculate the mean donation rate for each group\ndonation_rates = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ndonation_rates[\"Group\"] = donation_rates[\"treatment\"].map({1: \"Treatment\", 0: \"Control\"})\n\n# Create the barplot\nplt.figure(figsize=(6, 4))\nsns.barplot(data=donation_rates, x=\"Group\", y=\"gave\", palette=\"Blues_d\")\n\n# Label the chart\nplt.ylabel(\"Proportion Donated\")\nplt.xlabel(\"Group\")\nplt.title(\"Donation Response Rate: Treatment vs Control\")\nplt.ylim(0, 0.03)  # Set y-axis range for visual clarity\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n\n/tmp/ipykernel_88776/1362242253.py:10: FutureWarning:\n\n\n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n\n\n\n\n\n\n\n\n\n\n/tmp/ipykernel_1451/3587301648.py:10: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(data=donation_rates, x=\"Group\", y=\"gave\", palette=\"Blues_d\")\n\n\n\npng\n\n\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load the dataset\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Prepare ratio indicators\ndf[\"ratio\"] = df[\"ratio\"].astype(\"str\")\ndf[\"ratio1\"] = (df[\"ratio\"] == \"1\").astype(int)\ndf[\"ratio2\"] = (df[\"ratio\"] == \"2\").astype(int)\ndf[\"ratio3\"] = (df[\"ratio\"] == \"3\").astype(int)\n\n# Filter for treatment group only (exclude control group)\ndf_treat_only = df[df[\"treatment\"] == 1].copy()\n\n# T-tests: 1:1 vs 2:1 and 2:1 vs 3:1\ngave_1to1 = df_treat_only[df_treat_only[\"ratio1\"] == 1][\"gave\"]\ngave_2to1 = df_treat_only[df_treat_only[\"ratio2\"] == 1][\"gave\"]\ngave_3to1 = df_treat_only[df_treat_only[\"ratio3\"] == 1][\"gave\"]\n\nt_1v2, p_1v2, _ = sm.stats.ttest_ind(gave_1to1, gave_2to1)\nt_2v3, p_2v3, _ = sm.stats.ttest_ind(gave_2to1, gave_3to1)\n\n# Regression using dummy variables\nreg_dummy = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3 - 1\", data=df_treat_only).fit()\n\n# Regression using categorical variable\ndf_treat_only[\"ratio\"] = df_treat_only[\"ratio\"].astype(\"category\")\nreg_cat = smf.ols(\"gave ~ C(ratio)\", data=df_treat_only).fit()\n\n# Group means\ngroup_means = df_treat_only.groupby(\"ratio\")[\"gave\"].mean()\ndirect_diff_1v2 = group_means[\"2\"] - group_means[\"1\"]\ndirect_diff_2v3 = group_means[\"3\"] - group_means[\"2\"]\n\n# Regression differences\ncoef_1 = reg_dummy.params[\"ratio1\"]\ncoef_2 = reg_dummy.params[\"ratio2\"]\ncoef_3 = reg_dummy.params[\"ratio3\"]\nreg_diff_1v2 = coef_2 - coef_1\nreg_diff_2v3 = coef_3 - coef_2\n\n# Print summary\nprint(\"T-test p-value (1:1 vs 2:1):\", p_1v2)\nprint(\"T-test p-value (2:1 vs 3:1):\", p_2v3)\nprint(\"Direct difference in response rates (2:1 - 1:1):\", direct_diff_1v2)\nprint(\"Direct difference in response rates (3:1 - 2:1):\", direct_diff_2v3)\nprint(\"Regression-based difference (2:1 - 1:1):\", reg_diff_1v2)\nprint(\"Regression-based difference (3:1 - 2:1):\", reg_diff_2v3)\n\n# Optional: Show regression summaries\nprint(\"\\nOLS Regression with dummy variables:\")\nprint(reg_dummy.summary())\n\nprint(\"\\nOLS Regression with categorical variable:\")\nprint(reg_cat.summary())\n\nT-test p-value (1:1 vs 2:1): 0.3345316854972399\nT-test p-value (2:1 vs 3:1): 0.9600305283739325\nDirect difference in response rates (2:1 - 1:1): 0.0018842510217149944\nDirect difference in response rates (3:1 - 2:1): 0.00010002398025293902\nRegression-based difference (2:1 - 1:1): 0.0018842510217149805\nRegression-based difference (3:1 - 2:1): 0.00010002398025296677\n\nOLS Regression with dummy variables:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Wed, 14 May 2025   Prob (F-statistic):              0.524\nTime:                        12:18:14   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio1         0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0226      0.001     16.267      0.000       0.020       0.025\nratio3         0.0227      0.001     16.335      0.000       0.020       0.025\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         1.00\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nOLS Regression with categorical variable:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Wed, 14 May 2025   Prob (F-statistic):              0.524\nTime:                        12:18:14   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept         0.0207      0.001     14.912      0.000       0.018       0.023\nC(ratio)[T.2]     0.0019      0.002      0.958      0.338      -0.002       0.006\nC(ratio)[T.3]     0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n/tmp/ipykernel_88776/2038281865.py:33: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n\n\nT-test p-value (1:1 vs 2:1): 0.3345316854972399\nT-test p-value (2:1 vs 3:1): 0.9600305283739325\nDirect difference in response rates (2:1 - 1:1): 0.0018842510217149944\nDirect difference in response rates (3:1 - 2:1): 0.00010002398025293902\nRegression-based difference (2:1 - 1:1): 0.0018842510217149805\nRegression-based difference (3:1 - 2:1): 0.00010002398025296677\n\nOLS Regression with dummy variables:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):              0.524\nTime:                        02:00:40   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio1         0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0226      0.001     16.267      0.000       0.020       0.025\nratio3         0.0227      0.001     16.335      0.000       0.020       0.025\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         1.00\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nOLS Regression with categorical variable:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):              0.524\nTime:                        02:00:40   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept         0.0207      0.001     14.912      0.000       0.018       0.023\nC(ratio)[T.2]     0.0019      0.002      0.958      0.338      -0.002       0.006\nC(ratio)[T.3]     0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n/tmp/ipykernel_1451/3381687197.py:33: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  group_means = df_treat_only.groupby(\"ratio\")[\"gave\"].mean()\n\n\nüß™ Does Match Size Affect Donation Rates?\nWe test whether offering larger match ratios (e.g., 2:1 or 3:1) increases the likelihood of donating compared to a standard 1:1 match.\n\nüîç T-Test Results\n\n1:1 vs 2:1: No statistically significant difference (p ‚âà 0.335)\n2:1 vs 3:1: No statistically significant difference (p ‚âà 0.960)\n\n\n\nüìà Regression Results\nWe ran two regressions: 1. Using separate dummy variables (ratio1, ratio2, ratio3) ‚Äî one for each match level 2. Using a single categorical variable (C(ratio))\nBoth approaches yielded similar results: - Donation rate for 1:1 ‚âà 2.07% - Donation rate for 2:1 ‚âà 2.26% - Donation rate for 3:1 ‚âà 2.27% - Differences between them are very small and not statistically significant\n\n\nüìä Direct Comparison of Response Rates\n\n2:1 ‚Äì 1:1 ‚âà +0.19 percentage points\n3:1 ‚Äì 2:1 ‚âà +0.01 percentage points These findings match the regression results.\n\n\n\n‚úÖ Conclusion\nThese results support the authors‚Äô observatin that ‚ÄúThe figures suggest that larger match ratios have no additional impact.‚Äù\nüí° Key Insight: Donors respond to the presence of a match, but increasing the size of the match does not further increase the likelihood of donating.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Filter only those who made a donation\ndf_donors = df[df[\"gave\"] == 1]\n\n# Set up the plotting area\nplt.figure(figsize=(12, 5))\n\n# Histogram for Control Group\nplt.subplot(1, 2, 1)\ncontrol_amounts = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\nsns.histplot(control_amounts, bins=30, kde=False, color=\"skyblue\")\nplt.axvline(control_amounts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${control_amounts.mean():.2f}')\nplt.title(\"Donation Amounts - Control Group\")\nplt.xlabel(\"Amount Donated\")\nplt.ylabel(\"Number of Donors\")\nplt.legend()\n\n# Histogram for Treatment Group\nplt.subplot(1, 2, 2)\ntreatment_amounts = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\nsns.histplot(treatment_amounts, bins=30, kde=False, color=\"lightgreen\")\nplt.axvline(treatment_amounts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${treatment_amounts.mean():.2f}')\nplt.title(\"Donation Amounts - Treatment Group\")\nplt.xlabel(\"Amount Donated\")\nplt.ylabel(\"Number of Donors\")\nplt.legend()\n\n# Final layout\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nimport pandas as pd\n\n# Load the dataset (make sure the file is in the same directory as your notebook)\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Take a quick look at the first few rows\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\n\n\ncontrol\n\n\nratio\n\n\nratio2\n\n\nratio3\n\n\nsize\n\n\nsize25\n\n\nsize50\n\n\nsize100\n\n\nsizeno\n\n\n‚Ä¶\n\n\nredcty\n\n\nbluecty\n\n\npwhite\n\n\npblack\n\n\npage18_39\n\n\nave_hh_sz\n\n\nmedian_hhincome\n\n\npowner\n\n\npsch_atlstba\n\n\npop_propurban\n\n\n\n\n\n\n0\n\n\n0\n\n\n1\n\n\nControl\n\n\n0\n\n\n0\n\n\nControl\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n‚Ä¶\n\n\n0.0\n\n\n1.0\n\n\n0.446493\n\n\n0.527769\n\n\n0.317591\n\n\n2.10\n\n\n28517.0\n\n\n0.499807\n\n\n0.324528\n\n\n1.0\n\n\n\n\n1\n\n\n0\n\n\n1\n\n\nControl\n\n\n0\n\n\n0\n\n\nControl\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n‚Ä¶\n\n\n1.0\n\n\n0.0\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\n2\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n$100,000\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n‚Ä¶\n\n\n0.0\n\n\n1.0\n\n\n0.935706\n\n\n0.011948\n\n\n0.276128\n\n\n2.48\n\n\n51175.0\n\n\n0.721941\n\n\n0.192668\n\n\n1.0\n\n\n\n\n3\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\nUnstated\n\n\n0\n\n\n0\n\n\n0\n\n\n1\n\n\n‚Ä¶\n\n\n1.0\n\n\n0.0\n\n\n0.888331\n\n\n0.010760\n\n\n0.279412\n\n\n2.65\n\n\n79269.0\n\n\n0.920431\n\n\n0.412142\n\n\n1.0\n\n\n\n\n4\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n$50,000\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n‚Ä¶\n\n\n0.0\n\n\n1.0\n\n\n0.759014\n\n\n0.127421\n\n\n0.442389\n\n\n1.85\n\n\n40908.0\n\n\n0.416072\n\n\n0.439965\n\n\n1.0\n\n\n\n\n\n5 rows √ó 51 columns\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Calculate the mean donation rate for each group\ndonation_rates = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ndonation_rates[\"Group\"] = donation_rates[\"treatment\"].map({1: \"Treatment\", 0: \"Control\"})\n\n# Create the barplot\nplt.figure(figsize=(6, 4))\nsns.barplot(data=donation_rates, x=\"Group\", y=\"gave\", palette=\"Blues_d\")\n\n# Label the chart\nplt.ylabel(\"Proportion Donated\")\nplt.xlabel(\"Group\")\nplt.title(\"Donation Response Rate: Treatment vs Control\")\nplt.ylim(0, 0.03)  # Set y-axis range for visual clarity\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n/tmp/ipykernel_1451/3587301648.py:10: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(data=donation_rates, x=\"Group\", y=\"gave\", palette=\"Blues_d\")\n\n\n\npng\n\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load the dataset\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Prepare ratio indicators\ndf[\"ratio\"] = df[\"ratio\"].astype(\"str\")\ndf[\"ratio1\"] = (df[\"ratio\"] == \"1\").astype(int)\ndf[\"ratio2\"] = (df[\"ratio\"] == \"2\").astype(int)\ndf[\"ratio3\"] = (df[\"ratio\"] == \"3\").astype(int)\n\n# Filter for treatment group only (exclude control group)\ndf_treat_only = df[df[\"treatment\"] == 1].copy()\n\n# T-tests: 1:1 vs 2:1 and 2:1 vs 3:1\ngave_1to1 = df_treat_only[df_treat_only[\"ratio1\"] == 1][\"gave\"]\ngave_2to1 = df_treat_only[df_treat_only[\"ratio2\"] == 1][\"gave\"]\ngave_3to1 = df_treat_only[df_treat_only[\"ratio3\"] == 1][\"gave\"]\n\nt_1v2, p_1v2, _ = sm.stats.ttest_ind(gave_1to1, gave_2to1)\nt_2v3, p_2v3, _ = sm.stats.ttest_ind(gave_2to1, gave_3to1)\n\n# Regression using dummy variables\nreg_dummy = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3 - 1\", data=df_treat_only).fit()\n\n# Regression using categorical variable\ndf_treat_only[\"ratio\"] = df_treat_only[\"ratio\"].astype(\"category\")\nreg_cat = smf.ols(\"gave ~ C(ratio)\", data=df_treat_only).fit()\n\n# Group means\ngroup_means = df_treat_only.groupby(\"ratio\")[\"gave\"].mean()\ndirect_diff_1v2 = group_means[\"2\"] - group_means[\"1\"]\ndirect_diff_2v3 = group_means[\"3\"] - group_means[\"2\"]\n\n# Regression differences\ncoef_1 = reg_dummy.params[\"ratio1\"]\ncoef_2 = reg_dummy.params[\"ratio2\"]\ncoef_3 = reg_dummy.params[\"ratio3\"]\nreg_diff_1v2 = coef_2 - coef_1\nreg_diff_2v3 = coef_3 - coef_2\n\n# Print summary\nprint(\"T-test p-value (1:1 vs 2:1):\", p_1v2)\nprint(\"T-test p-value (2:1 vs 3:1):\", p_2v3)\nprint(\"Direct difference in response rates (2:1 - 1:1):\", direct_diff_1v2)\nprint(\"Direct difference in response rates (3:1 - 2:1):\", direct_diff_2v3)\nprint(\"Regression-based difference (2:1 - 1:1):\", reg_diff_1v2)\nprint(\"Regression-based difference (3:1 - 2:1):\", reg_diff_2v3)\n\n# Optional: Show regression summaries\nprint(\"\\nOLS Regression with dummy variables:\")\nprint(reg_dummy.summary())\n\nprint(\"\\nOLS Regression with categorical variable:\")\nprint(reg_cat.summary())\nT-test p-value (1:1 vs 2:1): 0.3345316854972399\nT-test p-value (2:1 vs 3:1): 0.9600305283739325\nDirect difference in response rates (2:1 - 1:1): 0.0018842510217149944\nDirect difference in response rates (3:1 - 2:1): 0.00010002398025293902\nRegression-based difference (2:1 - 1:1): 0.0018842510217149805\nRegression-based difference (3:1 - 2:1): 0.00010002398025296677\n\nOLS Regression with dummy variables:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):              0.524\nTime:                        02:00:40   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio1         0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0226      0.001     16.267      0.000       0.020       0.025\nratio3         0.0227      0.001     16.335      0.000       0.020       0.025\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         1.00\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nOLS Regression with categorical variable:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):              0.524\nTime:                        02:00:40   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept         0.0207      0.001     14.912      0.000       0.018       0.023\nC(ratio)[T.2]     0.0019      0.002      0.958      0.338      -0.002       0.006\nC(ratio)[T.3]     0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n/tmp/ipykernel_1451/3381687197.py:33: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  group_means = df_treat_only.groupby(\"ratio\")[\"gave\"].mean()\n\n\n\nüß™ Does Match Size Affect Donation Rates?\nWe test whether offering larger match ratios (e.g., 2:1 or 3:1) increases the likelihood of donating compared to a standard 1:1 match.\n\nüîç T-Test Results\n\n1:1 vs 2:1: No statistically significant difference (p ‚âà 0.335)\n2:1 vs 3:1: No statistically significant difference (p ‚âà 0.960)\n\n\n\nüìà Regression Results\nWe ran two regressions: 1. Using separate dummy variables (ratio1, ratio2, ratio3) ‚Äî one for each match level 2. Using a single categorical variable (C(ratio))\nBoth approaches yielded similar results: - Donation rate for 1:1 ‚âà 2.07% - Donation rate for 2:1 ‚âà 2.26% - Donation rate for 3:1 ‚âà 2.27% - Differences between them are very small and not statistically significant\n\n\nüìä Direct Comparison of Response Rates\n\n2:1 ‚Äì 1:1 ‚âà +0.19 percentage points\n3:1 ‚Äì 2:1 ‚âà +0.01 percentage points These findings match the regression results.\n\n\n\n‚úÖ Conclusion\nThese results support the authors‚Äô observatin that ‚ÄúThe figures suggest that larger match ratios have no additional impact.‚Äù\nüí° Key Insight: Donors respond to the presence of a match, but increasing the size of the match does not further increase the likelihood of donating.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Filter only those who made a donation\ndf_donors = df[df[\"gave\"] == 1]\n\n# Set up the plotting area\nplt.figure(figsize=(12, 5))\n\n# Histogram for Control Group\nplt.subplot(1, 2, 1)\ncontrol_amounts = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\nsns.histplot(control_amounts, bins=30, kde=False, color=\"skyblue\")\nplt.axvline(control_amounts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${control_amounts.mean():.2f}')\nplt.title(\"Donation Amounts - Control Group\")\nplt.xlabel(\"Amount Donated\")\nplt.ylabel(\"Number of Donors\")\nplt.legend()\n\n# Histogram for Treatment Group\nplt.subplot(1, 2, 2)\ntreatment_amounts = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\nsns.histplot(treatment_amounts, bins=30, kde=False, color=\"lightgreen\")\nplt.axvline(treatment_amounts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${treatment_amounts.mean():.2f}')\nplt.title(\"Donation Amounts - Treatment Group\")\nplt.xlabel(\"Amount Donated\")\nplt.ylabel(\"Number of Donors\")\nplt.legend()\n\n# Final layout\nplt.tight_layout()\nplt.show()\n\n\n\npng\n\n\n\n\n\nüíµ Size of Charitable Contribution\n\n‚úÖ Q1: Does treatment affect donation amount (all individuals)?\nWe performed both a t-test and a bivariate linear regression on the full dataset.\n\nT-test p-value: ~0.063\nRegression coefficient: +0.15 (Treatment vs.¬†Control)\nüìâ Interpretation:\n\nThe treatment group gave slightly more on average, but the difference is not statistically significant at the 5% level.\nThis suggests that while the match offer encourages more people to donate, it does not meaningfully affect how much they give, on average, across the full sample.\n\n\n\n\n\n‚úÖ Q2: Does treatment affect donation amount among donors only?\nWe repeated the analysis only for individuals who made a donation (i.e., gave == 1).\n\nT-test p-value: ~0.561\nRegression coefficient: ‚Äì1.67\nüìâ Interpretation:\n\nAmong donors, there is no statistically significant difference in how much was donated between the treatment and control groups.\nInterestingly, the control group gave slightly more, but this difference is small and not reliable.\n‚ö†Ô∏è Causal Note: This analysis does not have a causal interpretation, because it conditions on making a donation ‚Äî a behavior affected by the treatment. This introduces selection bias.\n\n\n\n\n\n‚úÖ Q3: What do the histograms show?\nWe created histograms of donation amounts among donors, separately for the treatment and control groups. Each plot includes:\n\nA red dashed line indicating the mean donation.\nThe distributions are highly right-skewed, with many small gifts and a few large ones.\n\nüìä Observations: - The average donation amount is very similar across the groups. - Most donations are clustered around $10‚Äì$50. - There is no visual evidence that treatment led to larger donations.\n\n\n\nüß† Final Takeaway:\nOffering a matching grant increases the probability of giving, but among those who give, it does not increase the amount given. This suggests that match offers primarily work as a participation nudge, not a generosity multiplier.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Simulate 10,000 Bernoulli trials\ncontrol_draws = np.random.binomial(1, 0.018, size=10000)\ntreatment_draws = np.random.binomial(1, 0.022, size=10000)\n\n# Calculate the difference at each draw\ndifferences = treatment_draws - control_draws\n\n# Compute the cumulative average of the differences\ncumulative_average = np.cumsum(differences) / np.arange(1, 10001)\n\n# Plot the cumulative average\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_average, label=\"Cumulative Average of Differences\")\nplt.axhline(0.004, color=\"red\", linestyle=\"--\", label=\"True Treatment Effect (0.004)\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average\")\nplt.title(\"Law of Large Numbers: Cumulative Average of Treatment - Control\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\npng\n\n\n\n\n\nüìà Law of Large Numbers: Simulating Donation Response Rates\nIn this simulation, we illustrate the Law of Large Numbers using synthetic data inspired by the charitable giving experiment.\n\nüéØ Setup:\n\nControl Group: Simulated with a Bernoulli distribution where the probability of donating is 1.8% (p = 0.018)\nTreatment Group: Simulated with a Bernoulli distribution where the probability of donating is 2.2% (p = 0.022)\nWe simulate 10,000 draws from each group and compute the difference (Treatment ‚Äì Control) for each pair.\nThen, we plot the cumulative average of those differences over time.\n\n\n\nüìä What the Graph Shows:\n\nThe line begins noisy due to early randomness.\nAs the number of draws increases, the average stabilizes and converges around the true treatment effect of 0.004 (2.2% - 1.8%).\nThe red dashed line marks this theoretical value.\n\n\n\nüß† Interpretation:\nThis visualization demonstrates the Law of Large Numbers: &gt; As the sample size grows, the sample average of a statistic will converge to its true population value.\nThis underlines why large-scale experiments (like the one in the Karlan & List paper) are powerful: with enough data, we can estimate effects reliably despite inherent randomness in individual behavior.\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Function to simulate the distribution of mean differences\ndef simulate_diff_distribution(sample_size, reps=1000):\n    differences = []\n    for _ in range(reps):\n        control_sample = np.random.binomial(1, 0.018, size=sample_size)\n        treatment_sample = np.random.binomial(1, 0.022, size=sample_size)\n        diff = treatment_sample.mean() - control_sample.mean()\n        differences.append(diff)\n    return differences\n\n# Sample sizes\nsample_sizes = [50, 200, 500, 1000]\n\n# Generate and plot each histogram separately\nfor size in sample_sizes:\n    diffs = simulate_diff_distribution(sample_size=size)\n    plt.figure(figsize=(7, 4))\n    sns.histplot(diffs, bins=30, kde=False, color=\"skyblue\")\n    plt.axvline(0.004, color='red', linestyle='--', linewidth=2, label=\"True Effect = 0.004\")\n    plt.title(f\"Sampling Distribution of Mean Differences (n = {size})\")\n    plt.xlabel(\"Mean Difference (Treatment - Control)\")\n    plt.ylabel(\"Frequency\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n\n\npng\n\n\n\n\n\npng\n\n\n\n\n\npng\n\n\n\n\n\npng\n\n\n\n\n\nüìä Central Limit Theorem Demonstration\nThis section visually demonstrates the Central Limit Theorem (CLT) using simulations based on the charitable giving experiment setup.\n\nüî¨ Method:\nFor each sample size ‚Äî n = 50, 200, 500, 1000: 1. We simulate 1,000 experiments. 2. In each experiment: - Take n samples from the control group (Bernoulli, p = 0.018) - Take n samples from the treatment group (Bernoulli, p = 0.022) - Compute the average difference in donation rates: treatment_mean - control_mean 3. We plot the histogram of the 1,000 average differences.\n\n\nüìà Interpretation of Histograms:\n\nFor n = 50, the distribution is wide and irregular ‚Äî highly affected by sampling noise.\nAs n increases (200, 500, 1000):\n\nThe distribution becomes tighter and smoother\nIt becomes centered around the true effect of 0.004 (shown by a red dashed line).\nThe shape begins to resemble a normal distribution.\n\n\n\n\nüß† Why It Matters:\nThis simulation illustrates the Central Limit Theorem: &gt; As sample size increases, the sampling distribution of the sample mean becomes approximately normal ‚Äî even when the underlying data are not normally distributed.\n‚úÖ Takeaway:\nThanks to the CLT, we can use normal-based inference methods (like t-tests and regression) when we have large enough samples ‚Äî as in the Karlan & List field experiment."
  },
  {
    "objectID": "hw1_questions.html#randomization-check-treatment-vs.-control-group-balance",
    "href": "hw1_questions.html#randomization-check-treatment-vs.-control-group-balance",
    "title": "A Replication of Karlan and List (2007)",
    "section": "‚úÖ Randomization Check: Treatment vs.¬†Control Group Balance",
    "text": "‚úÖ Randomization Check: Treatment vs.¬†Control Group Balance\nTo test the integrity of the random assignment, we compared several background variables between treatment and control groups using t-tests.\n\nüîç Variables Tested:\n\nmrm2: Months since last donation\n\nyears: Years since first donation\n\nhpa: Highest prior donation\n\nfemale: Female indicator\n\ncouple: Couple indicator\n\n\n\nüìà Key Findings:\n\nNo statistically significant differences (p &gt; 0.05) were found between groups for any variable tested.\nFor mrm2, both a t-test and a linear regression (mrm2 ~ treatment) produced the same result (p = 0.905), confirming the methods agree.\n\n\n\nüß† Why It Matters:\nThese tests confirm that the treatment and control groups were statistically similar before the intervention ‚Äî supporting the internal validity of the experiment.\nThis is the purpose of Table 1 in the paper: to demonstrate that any differences in donation behavior can be attributed to the matching grant treatment, not pre-existing group differences."
  },
  {
    "objectID": "hw1_questions.html#response-rate-by-treatment-group",
    "href": "hw1_questions.html#response-rate-by-treatment-group",
    "title": "A Replication of Karlan and List (2007)",
    "section": "üìä Response Rate by Treatment Group",
    "text": "üìä Response Rate by Treatment Group\nWe visualize whether being offered a matching donation affects the likelihood of donating. This barplot compares the donation response rate between the treatment and control groups.\n\nimport pandas as pd\n\n# Load the dataset (make sure the file is in the same directory as your notebook)\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Take a quick look at the first few rows\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows √ó 51 columns\n\n\n\n\n\n\n\n\n\n\n\ntreatment\n\n\ncontrol\n\n\nratio\n\n\nratio2\n\n\nratio3\n\n\nsize\n\n\nsize25\n\n\nsize50\n\n\nsize100\n\n\nsizeno\n\n\n‚Ä¶\n\n\nredcty\n\n\nbluecty\n\n\npwhite\n\n\npblack\n\n\npage18_39\n\n\nave_hh_sz\n\n\nmedian_hhincome\n\n\npowner\n\n\npsch_atlstba\n\n\npop_propurban\n\n\n\n\n\n\n0\n\n\n0\n\n\n1\n\n\nControl\n\n\n0\n\n\n0\n\n\nControl\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n‚Ä¶\n\n\n0.0\n\n\n1.0\n\n\n0.446493\n\n\n0.527769\n\n\n0.317591\n\n\n2.10\n\n\n28517.0\n\n\n0.499807\n\n\n0.324528\n\n\n1.0\n\n\n\n\n1\n\n\n0\n\n\n1\n\n\nControl\n\n\n0\n\n\n0\n\n\nControl\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n‚Ä¶\n\n\n1.0\n\n\n0.0\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\n2\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n$100,000\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n‚Ä¶\n\n\n0.0\n\n\n1.0\n\n\n0.935706\n\n\n0.011948\n\n\n0.276128\n\n\n2.48\n\n\n51175.0\n\n\n0.721941\n\n\n0.192668\n\n\n1.0\n\n\n\n\n3\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\nUnstated\n\n\n0\n\n\n0\n\n\n0\n\n\n1\n\n\n‚Ä¶\n\n\n1.0\n\n\n0.0\n\n\n0.888331\n\n\n0.010760\n\n\n0.279412\n\n\n2.65\n\n\n79269.0\n\n\n0.920431\n\n\n0.412142\n\n\n1.0\n\n\n\n\n4\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n$50,000\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n‚Ä¶\n\n\n0.0\n\n\n1.0\n\n\n0.759014\n\n\n0.127421\n\n\n0.442389\n\n\n1.85\n\n\n40908.0\n\n\n0.416072\n\n\n0.439965\n\n\n1.0\n\n\n\n\n\n5 rows √ó 51 columns\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Calculate the mean donation rate for each group\ndonation_rates = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ndonation_rates[\"Group\"] = donation_rates[\"treatment\"].map({1: \"Treatment\", 0: \"Control\"})\n\n# Create the barplot\nplt.figure(figsize=(6, 4))\nsns.barplot(data=donation_rates, x=\"Group\", y=\"gave\", palette=\"Blues_d\")\n\n# Label the chart\nplt.ylabel(\"Proportion Donated\")\nplt.xlabel(\"Group\")\nplt.title(\"Donation Response Rate: Treatment vs Control\")\nplt.ylim(0, 0.03)  # Set y-axis range for visual clarity\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n\n/tmp/ipykernel_88776/1362242253.py:10: FutureWarning:\n\n\n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n\n\n\n\n\n\n\n\n\n\n/tmp/ipykernel_1451/3587301648.py:10: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(data=donation_rates, x=\"Group\", y=\"gave\", palette=\"Blues_d\")\n\n\n\npng\n\n\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load the dataset\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Prepare ratio indicators\ndf[\"ratio\"] = df[\"ratio\"].astype(\"str\")\ndf[\"ratio1\"] = (df[\"ratio\"] == \"1\").astype(int)\ndf[\"ratio2\"] = (df[\"ratio\"] == \"2\").astype(int)\ndf[\"ratio3\"] = (df[\"ratio\"] == \"3\").astype(int)\n\n# Filter for treatment group only (exclude control group)\ndf_treat_only = df[df[\"treatment\"] == 1].copy()\n\n# T-tests: 1:1 vs 2:1 and 2:1 vs 3:1\ngave_1to1 = df_treat_only[df_treat_only[\"ratio1\"] == 1][\"gave\"]\ngave_2to1 = df_treat_only[df_treat_only[\"ratio2\"] == 1][\"gave\"]\ngave_3to1 = df_treat_only[df_treat_only[\"ratio3\"] == 1][\"gave\"]\n\nt_1v2, p_1v2, _ = sm.stats.ttest_ind(gave_1to1, gave_2to1)\nt_2v3, p_2v3, _ = sm.stats.ttest_ind(gave_2to1, gave_3to1)\n\n# Regression using dummy variables\nreg_dummy = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3 - 1\", data=df_treat_only).fit()\n\n# Regression using categorical variable\ndf_treat_only[\"ratio\"] = df_treat_only[\"ratio\"].astype(\"category\")\nreg_cat = smf.ols(\"gave ~ C(ratio)\", data=df_treat_only).fit()\n\n# Group means\ngroup_means = df_treat_only.groupby(\"ratio\")[\"gave\"].mean()\ndirect_diff_1v2 = group_means[\"2\"] - group_means[\"1\"]\ndirect_diff_2v3 = group_means[\"3\"] - group_means[\"2\"]\n\n# Regression differences\ncoef_1 = reg_dummy.params[\"ratio1\"]\ncoef_2 = reg_dummy.params[\"ratio2\"]\ncoef_3 = reg_dummy.params[\"ratio3\"]\nreg_diff_1v2 = coef_2 - coef_1\nreg_diff_2v3 = coef_3 - coef_2\n\n# Print summary\nprint(\"T-test p-value (1:1 vs 2:1):\", p_1v2)\nprint(\"T-test p-value (2:1 vs 3:1):\", p_2v3)\nprint(\"Direct difference in response rates (2:1 - 1:1):\", direct_diff_1v2)\nprint(\"Direct difference in response rates (3:1 - 2:1):\", direct_diff_2v3)\nprint(\"Regression-based difference (2:1 - 1:1):\", reg_diff_1v2)\nprint(\"Regression-based difference (3:1 - 2:1):\", reg_diff_2v3)\n\n# Optional: Show regression summaries\nprint(\"\\nOLS Regression with dummy variables:\")\nprint(reg_dummy.summary())\n\nprint(\"\\nOLS Regression with categorical variable:\")\nprint(reg_cat.summary())\n\nT-test p-value (1:1 vs 2:1): 0.3345316854972399\nT-test p-value (2:1 vs 3:1): 0.9600305283739325\nDirect difference in response rates (2:1 - 1:1): 0.0018842510217149944\nDirect difference in response rates (3:1 - 2:1): 0.00010002398025293902\nRegression-based difference (2:1 - 1:1): 0.0018842510217149805\nRegression-based difference (3:1 - 2:1): 0.00010002398025296677\n\nOLS Regression with dummy variables:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Wed, 14 May 2025   Prob (F-statistic):              0.524\nTime:                        12:18:14   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio1         0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0226      0.001     16.267      0.000       0.020       0.025\nratio3         0.0227      0.001     16.335      0.000       0.020       0.025\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         1.00\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nOLS Regression with categorical variable:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Wed, 14 May 2025   Prob (F-statistic):              0.524\nTime:                        12:18:14   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept         0.0207      0.001     14.912      0.000       0.018       0.023\nC(ratio)[T.2]     0.0019      0.002      0.958      0.338      -0.002       0.006\nC(ratio)[T.3]     0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n/tmp/ipykernel_88776/2038281865.py:33: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n\n\nT-test p-value (1:1 vs 2:1): 0.3345316854972399\nT-test p-value (2:1 vs 3:1): 0.9600305283739325\nDirect difference in response rates (2:1 - 1:1): 0.0018842510217149944\nDirect difference in response rates (3:1 - 2:1): 0.00010002398025293902\nRegression-based difference (2:1 - 1:1): 0.0018842510217149805\nRegression-based difference (3:1 - 2:1): 0.00010002398025296677\n\nOLS Regression with dummy variables:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):              0.524\nTime:                        02:00:40   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio1         0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0226      0.001     16.267      0.000       0.020       0.025\nratio3         0.0227      0.001     16.335      0.000       0.020       0.025\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         1.00\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nOLS Regression with categorical variable:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):              0.524\nTime:                        02:00:40   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept         0.0207      0.001     14.912      0.000       0.018       0.023\nC(ratio)[T.2]     0.0019      0.002      0.958      0.338      -0.002       0.006\nC(ratio)[T.3]     0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n/tmp/ipykernel_1451/3381687197.py:33: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  group_means = df_treat_only.groupby(\"ratio\")[\"gave\"].mean()"
  },
  {
    "objectID": "hw1_questions.html#does-match-size-affect-donation-rates",
    "href": "hw1_questions.html#does-match-size-affect-donation-rates",
    "title": "A Replication of Karlan and List (2007)",
    "section": "üß™ Does Match Size Affect Donation Rates?",
    "text": "üß™ Does Match Size Affect Donation Rates?\nWe test whether offering larger match ratios (e.g., 2:1 or 3:1) increases the likelihood of donating compared to a standard 1:1 match.\n\nüîç T-Test Results\n\n1:1 vs 2:1: No statistically significant difference (p ‚âà 0.335)\n2:1 vs 3:1: No statistically significant difference (p ‚âà 0.960)\n\n\n\nüìà Regression Results\nWe ran two regressions: 1. Using separate dummy variables (ratio1, ratio2, ratio3) ‚Äî one for each match level 2. Using a single categorical variable (C(ratio))\nBoth approaches yielded similar results: - Donation rate for 1:1 ‚âà 2.07% - Donation rate for 2:1 ‚âà 2.26% - Donation rate for 3:1 ‚âà 2.27% - Differences between them are very small and not statistically significant\n\n\nüìä Direct Comparison of Response Rates\n\n2:1 ‚Äì 1:1 ‚âà +0.19 percentage points\n3:1 ‚Äì 2:1 ‚âà +0.01 percentage points These findings match the regression results.\n\n\n\n‚úÖ Conclusion\nThese results support the authors‚Äô observatin that ‚ÄúThe figures suggest that larger match ratios have no additional impact.‚Äù\nüí° Key Insight: Donors respond to the presence of a match, but increasing the size of the match does not further increase the likelihood of donating.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Filter only those who made a donation\ndf_donors = df[df[\"gave\"] == 1]\n\n# Set up the plotting area\nplt.figure(figsize=(12, 5))\n\n# Histogram for Control Group\nplt.subplot(1, 2, 1)\ncontrol_amounts = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\nsns.histplot(control_amounts, bins=30, kde=False, color=\"skyblue\")\nplt.axvline(control_amounts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${control_amounts.mean():.2f}')\nplt.title(\"Donation Amounts - Control Group\")\nplt.xlabel(\"Amount Donated\")\nplt.ylabel(\"Number of Donors\")\nplt.legend()\n\n# Histogram for Treatment Group\nplt.subplot(1, 2, 2)\ntreatment_amounts = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\nsns.histplot(treatment_amounts, bins=30, kde=False, color=\"lightgreen\")\nplt.axvline(treatment_amounts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${treatment_amounts.mean():.2f}')\nplt.title(\"Donation Amounts - Treatment Group\")\nplt.xlabel(\"Amount Donated\")\nplt.ylabel(\"Number of Donors\")\nplt.legend()\n\n# Final layout\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nimport pandas as pd\n\n# Load the dataset (make sure the file is in the same directory as your notebook)\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Take a quick look at the first few rows\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\n\n\ncontrol\n\n\nratio\n\n\nratio2\n\n\nratio3\n\n\nsize\n\n\nsize25\n\n\nsize50\n\n\nsize100\n\n\nsizeno\n\n\n‚Ä¶\n\n\nredcty\n\n\nbluecty\n\n\npwhite\n\n\npblack\n\n\npage18_39\n\n\nave_hh_sz\n\n\nmedian_hhincome\n\n\npowner\n\n\npsch_atlstba\n\n\npop_propurban\n\n\n\n\n\n\n0\n\n\n0\n\n\n1\n\n\nControl\n\n\n0\n\n\n0\n\n\nControl\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n‚Ä¶\n\n\n0.0\n\n\n1.0\n\n\n0.446493\n\n\n0.527769\n\n\n0.317591\n\n\n2.10\n\n\n28517.0\n\n\n0.499807\n\n\n0.324528\n\n\n1.0\n\n\n\n\n1\n\n\n0\n\n\n1\n\n\nControl\n\n\n0\n\n\n0\n\n\nControl\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n‚Ä¶\n\n\n1.0\n\n\n0.0\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\n2\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n$100,000\n\n\n0\n\n\n0\n\n\n1\n\n\n0\n\n\n‚Ä¶\n\n\n0.0\n\n\n1.0\n\n\n0.935706\n\n\n0.011948\n\n\n0.276128\n\n\n2.48\n\n\n51175.0\n\n\n0.721941\n\n\n0.192668\n\n\n1.0\n\n\n\n\n3\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\nUnstated\n\n\n0\n\n\n0\n\n\n0\n\n\n1\n\n\n‚Ä¶\n\n\n1.0\n\n\n0.0\n\n\n0.888331\n\n\n0.010760\n\n\n0.279412\n\n\n2.65\n\n\n79269.0\n\n\n0.920431\n\n\n0.412142\n\n\n1.0\n\n\n\n\n4\n\n\n1\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n$50,000\n\n\n0\n\n\n1\n\n\n0\n\n\n0\n\n\n‚Ä¶\n\n\n0.0\n\n\n1.0\n\n\n0.759014\n\n\n0.127421\n\n\n0.442389\n\n\n1.85\n\n\n40908.0\n\n\n0.416072\n\n\n0.439965\n\n\n1.0\n\n\n\n\n\n5 rows √ó 51 columns\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Calculate the mean donation rate for each group\ndonation_rates = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ndonation_rates[\"Group\"] = donation_rates[\"treatment\"].map({1: \"Treatment\", 0: \"Control\"})\n\n# Create the barplot\nplt.figure(figsize=(6, 4))\nsns.barplot(data=donation_rates, x=\"Group\", y=\"gave\", palette=\"Blues_d\")\n\n# Label the chart\nplt.ylabel(\"Proportion Donated\")\nplt.xlabel(\"Group\")\nplt.title(\"Donation Response Rate: Treatment vs Control\")\nplt.ylim(0, 0.03)  # Set y-axis range for visual clarity\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n/tmp/ipykernel_1451/3587301648.py:10: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(data=donation_rates, x=\"Group\", y=\"gave\", palette=\"Blues_d\")\n\n\n\npng\n\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load the dataset\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Prepare ratio indicators\ndf[\"ratio\"] = df[\"ratio\"].astype(\"str\")\ndf[\"ratio1\"] = (df[\"ratio\"] == \"1\").astype(int)\ndf[\"ratio2\"] = (df[\"ratio\"] == \"2\").astype(int)\ndf[\"ratio3\"] = (df[\"ratio\"] == \"3\").astype(int)\n\n# Filter for treatment group only (exclude control group)\ndf_treat_only = df[df[\"treatment\"] == 1].copy()\n\n# T-tests: 1:1 vs 2:1 and 2:1 vs 3:1\ngave_1to1 = df_treat_only[df_treat_only[\"ratio1\"] == 1][\"gave\"]\ngave_2to1 = df_treat_only[df_treat_only[\"ratio2\"] == 1][\"gave\"]\ngave_3to1 = df_treat_only[df_treat_only[\"ratio3\"] == 1][\"gave\"]\n\nt_1v2, p_1v2, _ = sm.stats.ttest_ind(gave_1to1, gave_2to1)\nt_2v3, p_2v3, _ = sm.stats.ttest_ind(gave_2to1, gave_3to1)\n\n# Regression using dummy variables\nreg_dummy = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3 - 1\", data=df_treat_only).fit()\n\n# Regression using categorical variable\ndf_treat_only[\"ratio\"] = df_treat_only[\"ratio\"].astype(\"category\")\nreg_cat = smf.ols(\"gave ~ C(ratio)\", data=df_treat_only).fit()\n\n# Group means\ngroup_means = df_treat_only.groupby(\"ratio\")[\"gave\"].mean()\ndirect_diff_1v2 = group_means[\"2\"] - group_means[\"1\"]\ndirect_diff_2v3 = group_means[\"3\"] - group_means[\"2\"]\n\n# Regression differences\ncoef_1 = reg_dummy.params[\"ratio1\"]\ncoef_2 = reg_dummy.params[\"ratio2\"]\ncoef_3 = reg_dummy.params[\"ratio3\"]\nreg_diff_1v2 = coef_2 - coef_1\nreg_diff_2v3 = coef_3 - coef_2\n\n# Print summary\nprint(\"T-test p-value (1:1 vs 2:1):\", p_1v2)\nprint(\"T-test p-value (2:1 vs 3:1):\", p_2v3)\nprint(\"Direct difference in response rates (2:1 - 1:1):\", direct_diff_1v2)\nprint(\"Direct difference in response rates (3:1 - 2:1):\", direct_diff_2v3)\nprint(\"Regression-based difference (2:1 - 1:1):\", reg_diff_1v2)\nprint(\"Regression-based difference (3:1 - 2:1):\", reg_diff_2v3)\n\n# Optional: Show regression summaries\nprint(\"\\nOLS Regression with dummy variables:\")\nprint(reg_dummy.summary())\n\nprint(\"\\nOLS Regression with categorical variable:\")\nprint(reg_cat.summary())\nT-test p-value (1:1 vs 2:1): 0.3345316854972399\nT-test p-value (2:1 vs 3:1): 0.9600305283739325\nDirect difference in response rates (2:1 - 1:1): 0.0018842510217149944\nDirect difference in response rates (3:1 - 2:1): 0.00010002398025293902\nRegression-based difference (2:1 - 1:1): 0.0018842510217149805\nRegression-based difference (3:1 - 2:1): 0.00010002398025296677\n\nOLS Regression with dummy variables:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):              0.524\nTime:                        02:00:40   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio1         0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0226      0.001     16.267      0.000       0.020       0.025\nratio3         0.0227      0.001     16.335      0.000       0.020       0.025\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         1.00\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nOLS Regression with categorical variable:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Thu, 24 Apr 2025   Prob (F-statistic):              0.524\nTime:                        02:00:40   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept         0.0207      0.001     14.912      0.000       0.018       0.023\nC(ratio)[T.2]     0.0019      0.002      0.958      0.338      -0.002       0.006\nC(ratio)[T.3]     0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n/tmp/ipykernel_1451/3381687197.py:33: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  group_means = df_treat_only.groupby(\"ratio\")[\"gave\"].mean()"
  },
  {
    "objectID": "hw1_questions.html#size-of-charitable-contribution",
    "href": "hw1_questions.html#size-of-charitable-contribution",
    "title": "A Replication of Karlan and List (2007)",
    "section": "üíµ Size of Charitable Contribution",
    "text": "üíµ Size of Charitable Contribution\n\n‚úÖ Q1: Does treatment affect donation amount (all individuals)?\nWe performed both a t-test and a bivariate linear regression on the full dataset.\n\nT-test p-value: ~0.063\nRegression coefficient: +0.15 (Treatment vs.¬†Control)\nüìâ Interpretation:\n\nThe treatment group gave slightly more on average, but the difference is not statistically significant at the 5% level.\nThis suggests that while the match offer encourages more people to donate, it does not meaningfully affect how much they give, on average, across the full sample.\n\n\n\n\n\n‚úÖ Q2: Does treatment affect donation amount among donors only?\nWe repeated the analysis only for individuals who made a donation (i.e., gave == 1).\n\nT-test p-value: ~0.561\nRegression coefficient: ‚Äì1.67\nüìâ Interpretation:\n\nAmong donors, there is no statistically significant difference in how much was donated between the treatment and control groups.\nInterestingly, the control group gave slightly more, but this difference is small and not reliable.\n‚ö†Ô∏è Causal Note: This analysis does not have a causal interpretation, because it conditions on making a donation ‚Äî a behavior affected by the treatment. This introduces selection bias.\n\n\n\n\n\n‚úÖ Q3: What do the histograms show?\nWe created histograms of donation amounts among donors, separately for the treatment and control groups. Each plot includes:\n\nA red dashed line indicating the mean donation.\nThe distributions are highly right-skewed, with many small gifts and a few large ones.\n\nüìä Observations: - The average donation amount is very similar across the groups. - Most donations are clustered around $10‚Äì$50. - There is no visual evidence that treatment led to larger donations.\n\n\n\nüß† Final Takeaway:\nOffering a matching grant increases the probability of giving, but among those who give, it does not increase the amount given. This suggests that match offers primarily work as a participation nudge, not a generosity multiplier.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Simulate 10,000 Bernoulli trials\ncontrol_draws = np.random.binomial(1, 0.018, size=10000)\ntreatment_draws = np.random.binomial(1, 0.022, size=10000)\n\n# Calculate the difference at each draw\ndifferences = treatment_draws - control_draws\n\n# Compute the cumulative average of the differences\ncumulative_average = np.cumsum(differences) / np.arange(1, 10001)\n\n# Plot the cumulative average\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_average, label=\"Cumulative Average of Differences\")\nplt.axhline(0.004, color=\"red\", linestyle=\"--\", label=\"True Treatment Effect (0.004)\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average\")\nplt.title(\"Law of Large Numbers: Cumulative Average of Treatment - Control\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\npng"
  },
  {
    "objectID": "hw1_questions.html#law-of-large-numbers-simulating-donation-response-rates",
    "href": "hw1_questions.html#law-of-large-numbers-simulating-donation-response-rates",
    "title": "A Replication of Karlan and List (2007)",
    "section": "üìà Law of Large Numbers: Simulating Donation Response Rates",
    "text": "üìà Law of Large Numbers: Simulating Donation Response Rates\nIn this simulation, we illustrate the Law of Large Numbers using synthetic data inspired by the charitable giving experiment.\n\nüéØ Setup:\n\nControl Group: Simulated with a Bernoulli distribution where the probability of donating is 1.8% (p = 0.018)\nTreatment Group: Simulated with a Bernoulli distribution where the probability of donating is 2.2% (p = 0.022)\nWe simulate 10,000 draws from each group and compute the difference (Treatment ‚Äì Control) for each pair.\nThen, we plot the cumulative average of those differences over time.\n\n\n\nüìä What the Graph Shows:\n\nThe line begins noisy due to early randomness.\nAs the number of draws increases, the average stabilizes and converges around the true treatment effect of 0.004 (2.2% - 1.8%).\nThe red dashed line marks this theoretical value.\n\n\n\nüß† Interpretation:\nThis visualization demonstrates the Law of Large Numbers: &gt; As the sample size grows, the sample average of a statistic will converge to its true population value.\nThis underlines why large-scale experiments (like the one in the Karlan & List paper) are powerful: with enough data, we can estimate effects reliably despite inherent randomness in individual behavior.\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Function to simulate the distribution of mean differences\ndef simulate_diff_distribution(sample_size, reps=1000):\n    differences = []\n    for _ in range(reps):\n        control_sample = np.random.binomial(1, 0.018, size=sample_size)\n        treatment_sample = np.random.binomial(1, 0.022, size=sample_size)\n        diff = treatment_sample.mean() - control_sample.mean()\n        differences.append(diff)\n    return differences\n\n# Sample sizes\nsample_sizes = [50, 200, 500, 1000]\n\n# Generate and plot each histogram separately\nfor size in sample_sizes:\n    diffs = simulate_diff_distribution(sample_size=size)\n    plt.figure(figsize=(7, 4))\n    sns.histplot(diffs, bins=30, kde=False, color=\"skyblue\")\n    plt.axvline(0.004, color='red', linestyle='--', linewidth=2, label=\"True Effect = 0.004\")\n    plt.title(f\"Sampling Distribution of Mean Differences (n = {size})\")\n    plt.xlabel(\"Mean Difference (Treatment - Control)\")\n    plt.ylabel(\"Frequency\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n\n\npng\n\n\n\n\n\npng\n\n\n\n\n\npng\n\n\n\n\n\npng"
  },
  {
    "objectID": "hw1_questions.html#central-limit-theorem-demonstration",
    "href": "hw1_questions.html#central-limit-theorem-demonstration",
    "title": "A Replication of Karlan and List (2007)",
    "section": "üìä Central Limit Theorem Demonstration",
    "text": "üìä Central Limit Theorem Demonstration\nThis section visually demonstrates the Central Limit Theorem (CLT) using simulations based on the charitable giving experiment setup.\n\nüî¨ Method:\nFor each sample size ‚Äî n = 50, 200, 500, 1000: 1. We simulate 1,000 experiments. 2. In each experiment: - Take n samples from the control group (Bernoulli, p = 0.018) - Take n samples from the treatment group (Bernoulli, p = 0.022) - Compute the average difference in donation rates: treatment_mean - control_mean 3. We plot the histogram of the 1,000 average differences.\n\n\nüìà Interpretation of Histograms:\n\nFor n = 50, the distribution is wide and irregular ‚Äî highly affected by sampling noise.\nAs n increases (200, 500, 1000):\n\nThe distribution becomes tighter and smoother\nIt becomes centered around the true effect of 0.004 (shown by a red dashed line).\nThe shape begins to resemble a normal distribution.\n\n\n\n\nüß† Why It Matters:\nThis simulation illustrates the Central Limit Theorem: &gt; As sample size increases, the sampling distribution of the sample mean becomes approximately normal ‚Äî even when the underlying data are not normally distributed.\n‚úÖ Takeaway:\nThanks to the CLT, we can use normal-based inference methods (like t-tests and regression) when we have large enough samples ‚Äî as in the Karlan & List field experiment."
  },
  {
    "objectID": "hw1_questions.html#does-match-size-affect-donation-rates-1",
    "href": "hw1_questions.html#does-match-size-affect-donation-rates-1",
    "title": "A Replication of Karlan and List (2007)",
    "section": "üß™ Does Match Size Affect Donation Rates?",
    "text": "üß™ Does Match Size Affect Donation Rates?\nWe test whether offering larger match ratios (e.g., 2:1 or 3:1) increases the likelihood of donating compared to a standard 1:1 match.\n\nüîç T-Test Results\n\n1:1 vs 2:1: No statistically significant difference (p ‚âà 0.335)\n2:1 vs 3:1: No statistically significant difference (p ‚âà 0.960)\n\n\n\nüìà Regression Results\nWe ran two regressions: 1. Using separate dummy variables (ratio1, ratio2, ratio3) ‚Äî one for each match level 2. Using a single categorical variable (C(ratio))\nBoth approaches yielded similar results: - Donation rate for 1:1 ‚âà 2.07% - Donation rate for 2:1 ‚âà 2.26% - Donation rate for 3:1 ‚âà 2.27% - Differences between them are very small and not statistically significant\n\n\nüìä Direct Comparison of Response Rates\n\n2:1 ‚Äì 1:1 ‚âà +0.19 percentage points\n3:1 ‚Äì 2:1 ‚âà +0.01 percentage points These findings match the regression results.\n\n\n\n‚úÖ Conclusion\nThese results support the authors‚Äô observatin that ‚ÄúThe figures suggest that larger match ratios have no additional impact.‚Äù\nüí° Key Insight: Donors respond to the presence of a match, but increasing the size of the match does not further increase the likelihood of donating.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Filter only those who made a donation\ndf_donors = df[df[\"gave\"] == 1]\n\n# Set up the plotting area\nplt.figure(figsize=(12, 5))\n\n# Histogram for Control Group\nplt.subplot(1, 2, 1)\ncontrol_amounts = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\nsns.histplot(control_amounts, bins=30, kde=False, color=\"skyblue\")\nplt.axvline(control_amounts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${control_amounts.mean():.2f}')\nplt.title(\"Donation Amounts - Control Group\")\nplt.xlabel(\"Amount Donated\")\nplt.ylabel(\"Number of Donors\")\nplt.legend()\n\n# Histogram for Treatment Group\nplt.subplot(1, 2, 2)\ntreatment_amounts = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\nsns.histplot(treatment_amounts, bins=30, kde=False, color=\"lightgreen\")\nplt.axvline(treatment_amounts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${treatment_amounts.mean():.2f}')\nplt.title(\"Donation Amounts - Treatment Group\")\nplt.xlabel(\"Amount Donated\")\nplt.ylabel(\"Number of Donors\")\nplt.legend()\n\n# Final layout\nplt.tight_layout()\nplt.show()\n\n\n\npng"
  },
  {
    "objectID": "hw2_questions.html",
    "href": "hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "##testing\nBlueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty‚Äôs software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty‚Äôs software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm‚Äôs number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty‚Äôs software. The marketing team would like to use this data to make the claim that firms using Blueprinty‚Äôs software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you‚Äôre feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which ‚Äúfeels right‚Äù because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R‚Äôs optim() or Python‚Äôs sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1‚Äôs to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R‚Äôs glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty‚Äôs software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "hw2_questions.html#blueprinty-case-study",
    "href": "hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "##testing\nBlueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty‚Äôs software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty‚Äôs software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm‚Äôs number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty‚Äôs software. The marketing team would like to use this data to make the claim that firms using Blueprinty‚Äôs software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you‚Äôre feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which ‚Äúfeels right‚Äù because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R‚Äôs optim() or Python‚Äôs sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1‚Äôs to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R‚Äôs glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty‚Äôs software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "hw2_questions.html#airbnb-case-study",
    "href": "hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided.\nquarto render hw2_questions.qmd"
  },
  {
    "objectID": "mnl_estimation.html",
    "href": "mnl_estimation.html",
    "title": "Multinomial Logit Model Estimation",
    "section": "",
    "text": "We assume each individual selects the product with the highest utility. Given the utility specification:\n\\[\nU_{ij} = x_j'\\beta + \\epsilon_{ij}\n\\]\nand assuming \\(\\epsilon_{ij} \\sim \\text{i.i.d. Extreme Value}\\), the choice probability for product \\(j\\) is:\n\\[\n\\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^J e^{x_k'\\beta}}\n\\]\nThe likelihood for individual \\(i\\) is:\n\\[\nL_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}}\n\\]\nThe joint log-likelihood over all individuals is:\n\\[\n\\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j))\n\\]"
  },
  {
    "objectID": "mnl_estimation.html#likelihood-for-the-multinomial-logit-mnl-model",
    "href": "mnl_estimation.html#likelihood-for-the-multinomial-logit-mnl-model",
    "title": "Multinomial Logit Model Estimation",
    "section": "",
    "text": "We assume each individual selects the product with the highest utility. Given the utility specification:\n\\[\nU_{ij} = x_j'\\beta + \\epsilon_{ij}\n\\]\nand assuming \\(\\epsilon_{ij} \\sim \\text{i.i.d. Extreme Value}\\), the choice probability for product \\(j\\) is:\n\\[\n\\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^J e^{x_k'\\beta}}\n\\]\nThe likelihood for individual \\(i\\) is:\n\\[\nL_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}}\n\\]\nThe joint log-likelihood over all individuals is:\n\\[\n\\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j))\n\\]"
  },
  {
    "objectID": "mnl_estimation.html#simulate-conjoint-data",
    "href": "mnl_estimation.html#simulate-conjoint-data",
    "title": "Multinomial Logit Model Estimation",
    "section": "2. Simulate Conjoint Data",
    "text": "2. Simulate Conjoint Data\nWe simulate data for 100 respondents, each completing 10 choice tasks with 3 options. Attributes:\n\nBrand: Netflix, Prime, Hulu\nAds: Yes or No\nPrice: $8‚Äì$32\n\nTrue utilities:\n\n\\(\\beta_{\\text{Netflix}} = 1.0\\)\n\\(\\beta_{\\text{Prime}} = 0.5\\)\n\\(\\beta_{\\text{Ads}} = -0.8\\)\n\\(\\beta_{\\text{Price}} = -0.1\\)\n\nChoices are made by selecting the option with the highest utility, including Gumbel-distributed error."
  },
  {
    "objectID": "mnl_estimation.html#preparing-the-data-for-estimation",
    "href": "mnl_estimation.html#preparing-the-data-for-estimation",
    "title": "Multinomial Logit Model Estimation",
    "section": "3. Preparing the Data for Estimation",
    "text": "3. Preparing the Data for Estimation\n\nDummy variables were created for brand_N, brand_P, and ad_yes.\nbrand_H and ad_No are baseline categories.\nData was transformed into long format (each row = one alternative).\nGrouping by respondent and task is used for likelihood evaluation."
  },
  {
    "objectID": "mnl_estimation.html#estimation-via-maximum-likelihood",
    "href": "mnl_estimation.html#estimation-via-maximum-likelihood",
    "title": "Multinomial Logit Model Estimation",
    "section": "4. Estimation via Maximum Likelihood",
    "text": "4. Estimation via Maximum Likelihood\nMLEs using scipy.optimize.minimize():\n\n\n\nParameter\nEstimate\nStd. Error\n95% CI\n\n\n\n\n\\(\\beta_{\\text{Netflix}}\\)\n0.94\n0.10\n[0.74, 1.14]\n\n\n\\(\\beta_{\\text{Prime}}\\)\n0.50\n0.11\n[0.29, 0.71]\n\n\n\\(\\beta_{\\text{Ads}}\\)\n-0.73\n0.09\n[-0.90, -0.56]\n\n\n\\(\\beta_{\\text{Price}}\\)\n-0.10\n0.01\n[-0.11, -0.09]\n\n\n\nThese results align with the true simulation values."
  },
  {
    "objectID": "mnl_estimation.html#estimation-via-bayesian-methods",
    "href": "mnl_estimation.html#estimation-via-bayesian-methods",
    "title": "Multinomial Logit Model Estimation",
    "section": "5. Estimation via Bayesian Methods",
    "text": "5. Estimation via Bayesian Methods\nUsing Metropolis-Hastings with: - Priors: \\(\\mathcal{N}(0,5)\\) for dummies; \\(\\mathcal{N}(0,1)\\) for price - Proposal SD: [0.05, 0.05, 0.05, 0.005] - 2,000 iterations, 500 burn-in\nPosterior summary:\n\n\n\n\n\n\n\n\n\nParameter\nPosterior Mean\nStd. Dev.\n95% Credible Interval\n\n\n\n\n\\(\\beta_{\\text{Netflix}}\\)\n0.94\n0.11\n[0.74, 1.15]\n\n\n\\(\\beta_{\\text{Prime}}\\)\n0.50\n0.11\n[0.28, 0.71]\n\n\n\\(\\beta_{\\text{Ads}}\\)\n-0.72\n0.09\n[-0.88, -0.54]\n\n\n\\(\\beta_{\\text{Price}}\\)\n-0.10\n0.01\n[-0.11, -0.09]\n\n\n\nResults are consistent with MLE, validating the Bayesian approach."
  },
  {
    "objectID": "mnl_estimation.html#discussion",
    "href": "mnl_estimation.html#discussion",
    "title": "Multinomial Logit Model Estimation",
    "section": "6. Discussion",
    "text": "6. Discussion\n\na. Parameter Interpretation\n\n\\(\\beta_{\\text{Netflix}} &gt; \\beta_{\\text{Prime}}\\) implies respondents prefer Netflix to Prime.\nA negative \\(\\beta_{\\text{Price}}\\) reflects rational behavior: higher prices lower utility.\n\n\n\nb. Real-World Estimation (No Simulation)\n\nAssess model fit with predictive accuracy.\nPosterior intervals help assess uncertainty in estimates.\n\n\n\nc.¬†Extension to Hierarchical Bayes\n\nModel respondent-level parameters: \\(\\beta_i \\sim \\mathcal{N}(\\mu, \\Sigma)\\)\nEstimate hyperparameters \\((\\mu, \\Sigma)\\) across individuals.\nThis captures preference heterogeneity and is common in real-world conjoint analysis. /home/jovyan/git/MGTA 495 MARKETING ANALYTICS-howard/hw2_questions_files/libs"
  },
  {
    "objectID": "hw4_questions.html",
    "href": "hw4_questions.html",
    "title": "Machine Learning",
    "section": "",
    "text": "todo: do two analyses. Do one of either 1a or 1b, AND one of either 2a or 2b."
  },
  {
    "objectID": "hw4_questions.html#a.-k-means",
    "href": "hw4_questions.html#a.-k-means",
    "title": "Machine Learning",
    "section": "1a. K-Means",
    "text": "1a. K-Means\ntodo: write your own code to implement the k-means algorithm. Make plots of the various steps the algorithm takes so you can ‚Äúsee‚Äù the algorithm working. Test your algorithm on the Palmer Penguins dataset, specifically using the bill length and flipper length variables. Compare your results to the built-in kmeans function in R or Python.\ntodo: Calculate both the within-cluster-sum-of-squares and silhouette scores (you can use built-in functions to do so) and plot the results for various numbers of clusters (ie, K=2,3,‚Ä¶,7). What is the ‚Äúright‚Äù number of clusters as suggested by these two metrics?\nIf you want a challenge, add your plots as an animated gif on your website so that the result looks something like this."
  },
  {
    "objectID": "hw4_questions.html#b.-latent-class-mnl",
    "href": "hw4_questions.html#b.-latent-class-mnl",
    "title": "Machine Learning",
    "section": "1b. Latent-Class MNL",
    "text": "1b. Latent-Class MNL\ntodo: Use the Yogurt dataset to estimate a latent-class MNL model. This model was formally introduced in the paper by Kamakura & Russell (1989); you may want to read or reference page 2 of the pdf, which is described in the class slides, session 4, slides 56-57.\nThe data provides anonymized consumer identifiers (id), a vector indicating the chosen product (y1:y4), a vector indicating if any products were ‚Äúfeatured‚Äù in the store as a form of advertising (f1:f4), and the products‚Äô prices in price-per-ounce (p1:p4). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1‚Äôs purchase. Consumers 2 through 7 each bought yogurt 2, etc. You may want to reshape the data from its current ‚Äúwide‚Äù format into a ‚Äúlong‚Äù format.\ntodo: Fit the standard MNL model on these data. Then fit the latent-class MNL on these data separately for 2, 3, 4, and 5 latent classes.\ntodo: How many classes are suggested by the \\(BIC = -2*\\ell_n  + k*log(n)\\)? (where \\(\\ell_n\\) is the log-likelihood, \\(n\\) is the sample size, and \\(k\\) is the number of parameters.) The Bayesian-Schwarz Information Criterion link is a metric that assess the benefit of a better log likelihood at the expense of additional parameters to estimate ‚Äì akin to the adjusted R-squared for the linear regression model. Note, that a lower BIC indicates a better model fit, accounting for the number of parameters in the model.\ntodo: compare the parameter estimates between (1) the aggregate MNL, and (2) the latent-class MNL with the number of classes suggested by the BIC."
  },
  {
    "objectID": "hw4_questions.html#a.-k-nearest-neighbors",
    "href": "hw4_questions.html#a.-k-nearest-neighbors",
    "title": "Machine Learning",
    "section": "2a. K Nearest Neighbors",
    "text": "2a. K Nearest Neighbors\ntodo: use the following code (or the python equivalent) to generate a synthetic dataset for the k-nearest neighbors algorithm. The code generates a dataset with two features, x1 and x2, and a binary outcome variable y that is determined by whether x2 is above or below a wiggly boundary defined by a sin function.\n\n# gen data -----\nset.seed(42)\nn &lt;- 100\nx1 &lt;- runif(n, -3, 3)\nx2 &lt;- runif(n, -3, 3)\nx &lt;- cbind(x1, x2)\n\n# define a wiggly boundary\nboundary &lt;- sin(4*x1) + x1\ny &lt;- ifelse(x2 &gt; boundary, 1, 0) |&gt; as.factor()\ndat &lt;- data.frame(x1 = x1, x2 = x2, y = y)\n\ntodo: plot the data where the horizontal axis is x1, the vertical axis is x2, and the points are colored by the value of y. You may optionally draw the wiggly boundary.\ntodo: generate a test dataset with 100 points, using the same code as above but with a different seed.\ntodo: implement KNN by hand. Check you work with a built-in function ‚Äì eg, class::knn() or caret::train(method=\"knn\") in R, or scikit-learn‚Äôs KNeighborsClassifier in Python.\ntodo: run your function for k=1,‚Ä¶,k=30, each time noting the percentage of correctly-classified points from the test dataset. Plot the results, where the horizontal axis is 1-30 and the vertical axis is the percentage of correctly-classified points. What is the optimal value of k as suggested by your plot?"
  },
  {
    "objectID": "hw4_questions.html#b.-key-drivers-analysis",
    "href": "hw4_questions.html#b.-key-drivers-analysis",
    "title": "Machine Learning",
    "section": "2b. Key Drivers Analysis",
    "text": "2b. Key Drivers Analysis\ntodo: replicate the table on slide 75 of the session 5 slides. Specifically, using the dataset provided in the file data_for_drivers_analysis.csv, calculate: pearson correlations, standardized regression coefficients, ‚Äúusefulness‚Äù, Shapley values for a linear regression, Johnson‚Äôs relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python; you do not need to perform these calculations ‚Äúby hand.‚Äù\nIf you want a challenge, add additional measures to the table such as the importance scores from XGBoost, from a Neural Network, or from any additional method that measures the importance of variables."
  },
  {
    "objectID": "other_docs/hw4_questions.html",
    "href": "other_docs/hw4_questions.html",
    "title": "Machine Learning",
    "section": "",
    "text": "todo: do two analyses. Do one of either 1a or 1b, AND one of either 2a or 2b."
  },
  {
    "objectID": "other_docs/hw4_questions.html#a.-k-means",
    "href": "other_docs/hw4_questions.html#a.-k-means",
    "title": "Machine Learning",
    "section": "1a. K-Means",
    "text": "1a. K-Means\ntodo: write your own code to implement the k-means algorithm. Make plots of the various steps the algorithm takes so you can ‚Äúsee‚Äù the algorithm working. Test your algorithm on the Palmer Penguins dataset, specifically using the bill length and flipper length variables. Compare your results to the built-in kmeans function in R or Python.\ntodo: Calculate both the within-cluster-sum-of-squares and silhouette scores (you can use built-in functions to do so) and plot the results for various numbers of clusters (ie, K=2,3,‚Ä¶,7). What is the ‚Äúright‚Äù number of clusters as suggested by these two metrics?\nIf you want a challenge, add your plots as an animated gif on your website so that the result looks something like this."
  },
  {
    "objectID": "other_docs/hw4_questions.html#b.-latent-class-mnl",
    "href": "other_docs/hw4_questions.html#b.-latent-class-mnl",
    "title": "Machine Learning",
    "section": "1b. Latent-Class MNL",
    "text": "1b. Latent-Class MNL\ntodo: Use the Yogurt dataset to estimate a latent-class MNL model. This model was formally introduced in the paper by Kamakura & Russell (1989); you may want to read or reference page 2 of the pdf, which is described in the class slides, session 4, slides 56-57.\nThe data provides anonymized consumer identifiers (id), a vector indicating the chosen product (y1:y4), a vector indicating if any products were ‚Äúfeatured‚Äù in the store as a form of advertising (f1:f4), and the products‚Äô prices in price-per-ounce (p1:p4). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1‚Äôs purchase. Consumers 2 through 7 each bought yogurt 2, etc. You may want to reshape the data from its current ‚Äúwide‚Äù format into a ‚Äúlong‚Äù format.\ntodo: Fit the standard MNL model on these data. Then fit the latent-class MNL on these data separately for 2, 3, 4, and 5 latent classes.\ntodo: How many classes are suggested by the \\(BIC = -2*\\ell_n  + k*log(n)\\)? (where \\(\\ell_n\\) is the log-likelihood, \\(n\\) is the sample size, and \\(k\\) is the number of parameters.) The Bayesian-Schwarz Information Criterion link is a metric that assess the benefit of a better log likelihood at the expense of additional parameters to estimate ‚Äì akin to the adjusted R-squared for the linear regression model. Note, that a lower BIC indicates a better model fit, accounting for the number of parameters in the model.\ntodo: compare the parameter estimates between (1) the aggregate MNL, and (2) the latent-class MNL with the number of classes suggested by the BIC."
  },
  {
    "objectID": "other_docs/hw4_questions.html#a.-k-nearest-neighbors",
    "href": "other_docs/hw4_questions.html#a.-k-nearest-neighbors",
    "title": "Machine Learning",
    "section": "2a. K Nearest Neighbors",
    "text": "2a. K Nearest Neighbors\ntodo: use the following code (or the python equivalent) to generate a synthetic dataset for the k-nearest neighbors algorithm. The code generates a dataset with two features, x1 and x2, and a binary outcome variable y that is determined by whether x2 is above or below a wiggly boundary defined by a sin function.\n\n# gen data -----\nset.seed(42)\nn &lt;- 100\nx1 &lt;- runif(n, -3, 3)\nx2 &lt;- runif(n, -3, 3)\nx &lt;- cbind(x1, x2)\n\n# define a wiggly boundary\nboundary &lt;- sin(4*x1) + x1\ny &lt;- ifelse(x2 &gt; boundary, 1, 0) |&gt; as.factor()\ndat &lt;- data.frame(x1 = x1, x2 = x2, y = y)\n\ntodo: plot the data where the horizontal axis is x1, the vertical axis is x2, and the points are colored by the value of y. You may optionally draw the wiggly boundary.\ntodo: generate a test dataset with 100 points, using the same code as above but with a different seed.\ntodo: implement KNN by hand. Check you work with a built-in function ‚Äì eg, class::knn() or caret::train(method=\"knn\") in R, or scikit-learn‚Äôs KNeighborsClassifier in Python.\ntodo: run your function for k=1,‚Ä¶,k=30, each time noting the percentage of correctly-classified points from the test dataset. Plot the results, where the horizontal axis is 1-30 and the vertical axis is the percentage of correctly-classified points. What is the optimal value of k as suggested by your plot?"
  },
  {
    "objectID": "other_docs/hw4_questions.html#b.-key-drivers-analysis",
    "href": "other_docs/hw4_questions.html#b.-key-drivers-analysis",
    "title": "Machine Learning",
    "section": "2b. Key Drivers Analysis",
    "text": "2b. Key Drivers Analysis\ntodo: replicate the table on slide 75 of the session 5 slides. Specifically, using the dataset provided in the file data_for_drivers_analysis.csv, calculate: pearson correlations, standardized regression coefficients, ‚Äúusefulness‚Äù, Shapley values for a linear regression, Johnson‚Äôs relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python; you do not need to perform these calculations ‚Äúby hand.‚Äù\nIf you want a challenge, add additional measures to the table such as the importance scores from XGBoost, from a Neural Network, or from any additional method that measures the importance of variables."
  }
]